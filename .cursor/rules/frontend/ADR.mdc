---
description: Frontend Architectural Decision Records
globs:
alwaysApply: false
---

# Architecture Decision Log - Frontend

<!--
ADR_AGENT_PROTOCOL v1.0

You (the agent) manage this file as the single source of truth for all frontend ADRs.

NUMBER RANGE CONVENTION
- Platform ADRs: ADR-0001 to ADR-0999 (.cursor/rules/ADR.mdc)
- Frontend ADRs: ADR-1000 to ADR-1999 (.cursor/rules/frontend/ADR.mdc)
- Backend Infrastructure: ADR-2000 to ADR-2049 (.cursor/rules/backend/ADR.mdc)
- Backend Grant Prototype: ADR-2050 to ADR-2099 (.cursor/rules/backend/grant-prototype/ADR.mdc)
- Backend Grant ADK: ADR-2100 to ADR-2499 (.cursor/rules/backend/ADR.mdc)

INVARIANTS
- Keep this exact file structure and headings.
- All ADR entries use H2 headings: "## ADR-XXXX — <Title>" (4-digit zero-padded ID).
- Frontend ADRs MUST use numbers 1000-1999 only.
- Allowed Status values: Proposed | Accepted | Superseded
- Date format: YYYY-MM-DD
- New entries must be appended to the END of the file.
- The Index table between the INDEX markers must always reflect the latest state and be sorted by ID desc (newest on top).
- Each ADR MUST contain: Date, Status, Owner, Context, Decision, Consequences.
- Each ADR must include an explicit anchor `<a id="adr-XXXX"></a>` so links remain stable.

HOW TO ADD A NEW ADR
1) Read the whole file.
2) Compute next ID:
   - Scan for headings matching: ^## ADR-(\d{4}) — .+$
   - next_id = (max captured number) + 1, left-pad to 4 digits.
   - Ensure ID is in range 1000-1999.
3) Create a new ADR section using the "New ADR Entry Template" below.
   - Place it AFTER the last ADR section in the file.
   - Add an `<a id="adr-XXXX"></a>` line immediately below the heading.
4) Update the Index (between the INDEX markers):
   - Insert/replace the row for this ADR keeping the table sorted by ID descending.
   - Title in the Index MUST link to the anchor: [<Title>](#adr-XXXX)
   - If this ADR supersedes another: set "Supersedes" in this row, and update that older ADR:
       a) Change its Status to "Superseded"
       b) Add "Superseded by: ADR-XXXX" in its Consequences block
       c) Update the older ADR's Index row "Superseded by" column to ADR-XXXX
5) Validate before saving:
   - Exactly one heading exists for ADR-XXXX
   - All required fields are present and non-empty
   - Index contains a row for ADR-XXXX and remains properly sorted
6) Concurrency resolution:
   - If a merge conflict or duplicate ID is detected after reading: recompute next_id from the current file state, rename your heading, anchor, and Index row accordingly, and retry once.

COMMIT MESSAGE SUGGESTION
- "ADR-XXXX: <Short Title> — <Status>"

END ADR_AGENT_PROTOCOL
-->

## Index

<!-- BEGIN:ADR_INDEX -->

| ID   | Title                                                      | Date       | Status   | Supersedes | Superseded by |
| ---- | ---------------------------------------------------------- | ---------- | -------- | ---------- | ------------- |
| 1008 | [Test Evidence Organization by Grant](#adr-1008)          | 2025-11-15 | Accepted | —          | —             |
| 1007 | [Playwright MCP Browser Testing Before PR](#adr-1007)     | 2025-11-15 | Accepted | —          | —             |
| 1006 | [URL Structure for Multi-Grant Multi-Client Scale](#adr-1006) | 2025-11-13 | Accepted | —          | —             |
| 1005 | [PDF Export Strategy](#adr-1005)                          | 2025-11-12 | Accepted | —          | —             |
| 1004 | [Collaboration Backend Decision](#adr-1004)               | 2025-11-12 | Proposed | —          | —             |
| 1003 | [Multi-Step Form State Management](#adr-1003)             | 2025-11-12 | Accepted | —          | —             |
| 1002 | [Schema-Driven Form Generation](#adr-1002)                | 2025-11-12 | Accepted | —          | —             |
| 1001 | [React Hook Form + Shadcn UI Foundation](#adr-1001)       | 2025-11-12 | Accepted | —          | —             |

<!-- END:ADR_INDEX -->

<!-- REMEMBER: When adding new ADR, also update Index table above! -->

---

## New ADR Entry Template (copy for each new decision)

> Replace placeholders, keep section headers. Keep prose concise.

```

## ADR-XXXX — <Short, specific title>

<a id="adr-XXXX"></a>
**Date**: YYYY-MM-DD
**Status**: Proposed | Accepted | Superseded
**Owner**: <Name>

### Context

<1–3 sentences: what changed or what forces drive this decision now>

### Alternatives

<Quick bullet list of alternatives considered, and why they were rejected.>

### Decision

<Single clear decision in active voice; make it testable/verifiable>

### Consequences

* **Pros**: <benefit 1>, <benefit 2>
* **Cons / risks**: <cost 1>, <risk 1>
* **Supersedes**: ADR-NNNN (if any)
* **Superseded by**: ADR-MMMM (filled later if replaced)

### (Optional) Compliance / Verification

<How we'll check this is honored: tests, checks, fitness functions, runbooks>

```

---

## ADR-1001 — React Hook Form + Shadcn UI Foundation

<a id="adr-1001"></a>
**Date**: 2025-11-12
**Status**: Accepted
**Owner**: Grant-Harness Team

### Context

Week 2-4 prototype requires replicating government grant application forms in Next.js. Forms have complex validation, multi-step workflows, conditional fields, and must match government portal styling. Need a form library that supports dynamic schema-driven generation from scraped grant application structures while maintaining type safety and modern UX.

### Alternatives

* **React Hook Form + Shadcn UI (chosen)**:
  - Pros: Minimal re-renders (performance), Zod integration for type-safe validation, Shadcn UI provides government-appropriate styling, large community, works well with dynamic schemas
  - Cons: Manual form generation (not auto-generated from schema out-of-box)

* **Formik + Material-UI**:
  - Pros: Mature ecosystem, auto-generated forms possible
  - Cons: Heavier bundle, more re-renders, Material-UI styling doesn't match government portals

* **SurveyJS**:
  - Pros: Complete form builder, JSON-based, PDF export built-in
  - Cons: Commercial license required, overkill for prototype, doesn't support our specific collaboration requirements

* **Custom form system**:
  - Pros: Complete control
  - Cons: Weeks of development, reinventing wheel

### Decision

Use **React Hook Form + Shadcn UI** as the foundation for all grant application forms:

**Core Tech Stack**:
- **Next.js 15.x** (App Router) - Latest stable version with React 19 support
- **React 19.x** - Modern React with concurrent features and improved form handling
- **TypeScript 5.1+** - Type safety and developer experience
- **Node.js 20.9+** - Required for Next.js 15
- **Tailwind CSS 3.4+** - Utility-first CSS framework (via Shadcn UI)

**Rationale for Next.js 15**:
- React 19 compatibility (v16 too new/unstable, v14 stuck on React 18)
- Stable ecosystem support (Shadcn UI fully compatible)
- Modern App Router features (async components, server actions)
- Active LTS with security updates through 2025
- Avoids breaking changes in v16 (async params, AMP removal)

**React Hook Form** (form state management):
- Uncontrolled components for performance
- Zod resolver for validation from schemas
- Watch API for conditional fields
- Client-side validation (compatible with React 19)

**Shadcn UI** (component library):
- Tailwind-based components (easy to customize for government styling)
- Accessible by default (WCAG compliance)
- Copy-paste components (not a dependency - full control)
- Form components: Input, Textarea, Select, Radio Group, Checkbox
- React 19 compatible (tested with latest release)

**Base template**: Clone `shadcn-nextjs-multistep-form-example` (https://github.com/63r6o/shadcn-nextjs-multistep-form-example) as starting point

### Consequences

* **Pros**:
  - Type-safe forms with Zod validation
  - Fast performance (uncontrolled components, minimal re-renders)
  - Government-appropriate styling (Shadcn UI easily customizable)
  - Multi-step form pattern well-established in template
  - Save/resume functionality via LocalStorage (built into template)
  - AI-friendly (easy to programmatically populate form values)

* **Cons / risks**:
  - Must build dynamic form generator (not built-in)
  - Shadcn UI components must be copied into project (increases codebase size)
  - Learning curve for Shadcn UI patterns (mitigated by template)

* **Supersedes**: —

### Compliance / Verification

**Evidence Files**:
- `front/grant-portal/package.json` - Includes `react-hook-form`, `@hookform/resolvers`, `zod`
- `front/grant-portal/components/ui/` - Shadcn UI components installed
- `front/grant-portal/app/applications/[grantId]/page.tsx` - Dynamic form using React Hook Form

**Verification**:
- Week 2: IGP form uses React Hook Form + Shadcn UI
- Week 2: Form validation works with Zod schema
- Week 2: Form styling matches government portal (stakeholder confirms)

**AI Agent Guidance**: Always use React Hook Form for form state. Use Zod for validation schemas. Install Shadcn UI components via `npx shadcn-ui@latest add <component>`. Never use other form libraries. Reference template at https://github.com/63r6o/shadcn-nextjs-multistep-form-example for multi-step patterns.

---

## ADR-1002 — Schema-Driven Form Generation

<a id="adr-1002"></a>
**Date**: 2025-11-12
**Status**: Accepted
**Owner**: Grant-Harness Team

### Context

Each grant has unique application forms (different fields, validation rules, conditional logic). Industry Growth Program has ~45 fields across 8 steps. Battery Breakthrough Initiative has ~60 fields with complex conditional sections. Cannot manually code each form - need programmatic generation from schemas extracted via `/analyze-application` command.

### Alternatives

* **Manual form coding**:
  - Pros: Full control, explicit validation
  - Cons: Weeks per form, unmaintainable, doesn't scale

* **Schema-driven generation (chosen)**:
  - Pros: One schema → one form, scalable, AI can generate schemas from PDFs
  - Cons: Must build form generator, complex conditional logic requires careful schema design

* **Form builder UI (SurveyJS)**:
  - Pros: Visual form builder
  - Cons: Commercial license, doesn't integrate with our AI population workflow

### Decision

Implement **schema-driven dynamic form generation** where each grant's application form is defined as a JSON schema, and a `DynamicForm` component renders it:

**Schema format** (stored in `front/grant-portal/lib/schemas/{grant-id}.ts`):
```typescript
export const industryGrowthProgramSchema = {
  grant_id: "igp-2025",
  grant_name: "Industry Growth Program",
  steps: [
    {
      id: "eligibility",
      name: "Eligibility Check",
      fields: [
        {
          id: "abn",
          type: "text",
          label: "Australian Business Number (ABN)",
          required: true,
          validation: { pattern: /^\d{11}$/, message: "ABN must be 11 digits" }
        },
        {
          id: "employee_count",
          type: "number",
          label: "Number of Full-Time Employees",
          required: true,
          validation: { min: 1, max: 10000 }
        }
        // ... more fields
      ]
    },
    {
      id: "company_details",
      name: "Company Details",
      fields: [...]
    }
    // ... more steps
  ]
}
```

**Dynamic form renderer**:
```tsx
<DynamicForm schema={grantSchema} onSubmit={handleSubmit}>
  {/* Automatically generates all steps and fields */}
</DynamicForm>
```

**Field types supported**: `text`, `textarea`, `number`, `select`, `radio`, `checkbox`, `date`, `file`, `currency`, `address`, `abn`

**Conditional fields**: Support `showIf` conditions in schema (e.g., show "Export countries" only if "Exporting" is "Yes")

**Integration with `/analyze-application`**: Python command extracts form structure from PDF → generates TypeScript schema file

### Consequences

* **Pros**:
  - Scalable: Add new grant = add new schema (not recode entire form)
  - AI-friendly: Schema extraction from PDFs via LLM
  - Type-safe: Zod schema auto-generated from JSON schema
  - Maintainable: Update form = update schema JSON (not React components)
  - Testable: Schema validation separate from UI

* **Cons / risks**:
  - Complex conditional logic hard to express in schema (mitigated: start with simple grants)
  - Dynamic rendering can be harder to debug than explicit JSX
  - Schema design requires careful planning

* **Supersedes**: —

### Compliance / Verification

**Evidence Files**:
- `front/grant-portal/lib/schemas/igp.ts` - IGP schema generated from `/analyze-application`
- `front/grant-portal/components/forms/DynamicForm.tsx` - Schema renderer
- `front/grant-portal/components/forms/DynamicField.tsx` - Field type router

**Verification**:
- Week 2: `/analyze-application igp` generates valid schema
- Week 2: `DynamicForm` renders IGP form from schema
- Week 2: All field types work (text, number, select, etc.)

**Reference**: https://github.com/ansyg/nextjs-shadcn-dynamic-form for schema-driven patterns

**AI Agent Guidance**: Every grant gets a schema in `lib/schemas/{grant-id}.ts`. Use `/analyze-application` to extract schema from grant PDFs. DynamicForm component handles rendering. Add new field types to DynamicField component as needed. Keep schemas simple initially - add conditional logic only when required.

---

## ADR-1003 — Multi-Step Form State Management

<a id="adr-1003"></a>
**Date**: 2025-11-12
**Status**: Accepted
**Owner**: Grant-Harness Team

### Context

Grant applications have 5-10 steps (Eligibility → Company Details → Project Details → Financials → Documents → Review → Submit). Users must be able to navigate between steps, save progress, and resume later. Week 3 adds multi-user collaboration where consultant and client review same application simultaneously. Need state management for form data across steps and users.

### Alternatives

* **React Context API (chosen)**:
  - Pros: Built into React, simple for prototype, localStorage persistence easy, no dependencies
  - Cons: Re-renders on state change (mitigated by Context optimization)

* **Redux Toolkit**:
  - Pros: Powerful, time-travel debugging
  - Cons: Overkill for prototype, boilerplate overhead, learning curve

* **Zustand**:
  - Pros: Minimal API, good performance
  - Cons: Another dependency, less familiar

* **React Hook Form only** (no global state):
  - Pros: Simplest
  - Cons: Loses data on step navigation, can't persist across sessions

### Decision

Use **React Context API** for multi-step form state management:

**FormContext** provides:
- Current step tracking
- Form data for all steps
- Navigation methods (`nextStep`, `prevStep`, `goToStep`)
- Save/resume to localStorage
- Validation state per step

**Pattern** (from shadcn-nextjs-multistep-form-example):
```tsx
<FormProvider>
  <MultiStepForm schema={grantSchema}>
    <StepIndicator /> {/* Shows "Step 2 of 8" */}
    <StepContent /> {/* Renders current step's fields */}
    <StepNavigation /> {/* Previous/Next buttons */}
  </MultiStepForm>
</FormProvider>
```

**localStorage persistence**:
```typescript
// Auto-save on field change
const saveToLocalStorage = debounce((formData) => {
  localStorage.setItem(`application-${applicationId}`, JSON.stringify(formData))
}, 1000)

// Auto-resume on mount
useEffect(() => {
  const saved = localStorage.getItem(`application-${applicationId}`)
  if (saved) setFormData(JSON.parse(saved))
}, [])
```

**Week 3 enhancement**: Replace localStorage with Supabase/Firebase for real-time sync (see ADR-1004)

### Consequences

* **Pros**:
  - Zero dependencies (Context API built-in)
  - Save/resume works immediately (localStorage)
  - Simple to understand and debug
  - Easy migration to Supabase later (swap localStorage for database)
  - Works offline (localStorage)

* **Cons / risks**:
  - localStorage limited to 5-10MB (acceptable for forms)
  - No multi-device sync (until Week 3 Supabase integration)
  - Context re-renders on any state change (mitigated: split contexts by concern)

* **Supersedes**: —

### Compliance / Verification

**Evidence Files**:
- `front/grant-portal/lib/contexts/FormContext.tsx` - Form state provider
- `front/grant-portal/components/forms/MultiStepForm.tsx` - Multi-step wrapper
- `front/grant-portal/components/forms/StepIndicator.tsx` - Progress indicator

**Verification**:
- Week 2: Navigate between steps without losing data
- Week 2: Close browser, reopen → form data persists
- Week 3: Replace localStorage with Supabase (see ADR-1004)

**Reference**: https://github.com/63r6o/shadcn-nextjs-multistep-form-example for Context pattern

**AI Agent Guidance**: Use FormContext for all form state. Never use component-level useState for form data (will lose on step change). Persist to localStorage on every change (debounced 1s). In Week 3, replace localStorage with Supabase but keep Context API structure.

---

## ADR-1004 — Collaboration Backend Decision

<a id="adr-1004"></a>
**Date**: 2025-11-12
**Status**: Proposed
**Owner**: Grant-Harness Team

### Context

Week 3 requires multi-stakeholder collaboration: consultant populates form, flags fields for review, CFO edits financial sections, CEO approves final draft. Need real-time updates, field-level comments, approval workflow, and audit trail. Currently using localStorage (ADR-1003) which is single-user only.

**Decision required by**: Day 13 (Week 3 start)

### Alternatives

* **Supabase**:
  - Pros: PostgreSQL + real-time subscriptions, Auth built-in, generous free tier, easy Vercel deployment, Row Level Security for access control
  - Cons: Vendor lock-in, requires database schema design

* **Firebase**:
  - Pros: Real-time database, Auth built-in, Google ecosystem, easy setup
  - Cons: NoSQL (harder for relational data like applications), pricing can escalate

* **Custom backend (FastAPI + PostgreSQL + WebSockets)**:
  - Pros: Full control, no vendor lock-in
  - Cons: 1-2 weeks to build, overkill for prototype, deployment complexity

* **Defer to Phase 2**:
  - Pros: Focus on form generation first
  - Cons: Can't demonstrate collaboration workflow (critical value prop)

### Decision

**Propose Supabase** (pending Week 3 evaluation):

**Why Supabase**:
- Real-time subscriptions for live collaboration
- PostgreSQL for structured data (applications, comments, approvals)
- Row Level Security for multi-tenant (consultant sees only their clients)
- Auth with email/password (consultant, CEO, CFO login)
- Free tier sufficient for prototype (up to 500MB DB, 2GB bandwidth)

**Schema design**:
```sql
-- Applications table
applications (
  id uuid primary key,
  company_id text,
  grant_id text,
  form_data jsonb,  -- All form fields
  status text,      -- draft | in_review | approved | submitted
  created_by uuid,
  updated_at timestamp
)

-- Comments table (field-level)
comments (
  id uuid primary key,
  application_id uuid,
  field_id text,
  content text,
  author_id uuid,
  created_at timestamp
)

-- Approvals table
approvals (
  id uuid primary key,
  application_id uuid,
  approver_id uuid,
  status text,      -- pending | approved | rejected
  comments text,
  approved_at timestamp
)
```

**Alternative if Supabase blocked**: Firebase Firestore (same schema, slightly different API)

### Consequences

* **Pros** (if Supabase chosen):
  - Real-time collaboration ready in 2-3 days (vs 2 weeks custom backend)
  - PostgreSQL for complex queries (e.g., "Show all pending approvals")
  - Auth handled (consultant/CEO/CFO login)
  - Scales to Phase 2 (multi-company dashboard)

* **Cons / risks**:
  - Vendor lock-in to Supabase (mitigated: can export PostgreSQL dump)
  - Learning curve for team (mitigated: excellent docs)
  - Pricing unknown at scale (free tier → $25/mo at ~1GB, acceptable)

* **Supersedes**: localStorage-only approach (ADR-1003)

### Compliance / Verification

**Evidence Files** (to be created Week 3):
- `front/grant-portal/lib/supabase/client.ts` - Supabase client setup
- `front/grant-portal/lib/supabase/schema.sql` - Database schema
- `front/grant-portal/hooks/useApplicationSync.ts` - Real-time sync hook

**Verification** (Week 3):
- Two users editing same form see real-time updates
- Field-level comments appear instantly
- Approval workflow tracks all changes

**AI Agent Guidance**: Decision will be finalized at start of Week 3. If Supabase chosen, create schema in Supabase dashboard, configure environment variables, replace FormContext localStorage calls with Supabase queries. If Firebase chosen, use Firestore collections instead. Do NOT build custom backend.

---

## ADR-1005 — PDF Export Strategy

<a id="adr-1005"></a>
**Date**: 2025-11-12
**Status**: Accepted
**Owner**: Grant-Harness Team

### Context

Week 4 requires exporting completed application forms to PDF format matching government portal styling (fonts, margins, headers, section breaks). Some grants accept PDF uploads, others require manual portal entry (PDF serves as review document). Need PDF generation that preserves form structure, includes supporting documents as appendices, and optionally includes digital signatures.

### Alternatives

* **react-pdf (@react-pdf/renderer)**:
  - Pros: React components → PDF, good control, client-side generation
  - Cons: Must rebuild entire form layout in PDF components (duplication)

* **Puppeteer (server-side)**:
  - Pros: Print browser view to PDF (no layout duplication)
  - Cons: Requires backend, heavy (full Chrome), slower

* **jsPDF + html2canvas**:
  - Pros: Client-side, converts HTML to PDF directly
  - Cons: Inconsistent rendering, poor handling of multi-page content

* **Government portal scraping (Playwright)**:
  - Pros: Submits directly to portal
  - Cons: Brittle (portals change), complex per-grant, illegal for some portals

### Decision

Use **hybrid approach**:

**For PDF-accepting grants**: react-pdf (@react-pdf/renderer)
- Create PDF template matching government format
- Populate from form data
- Include supporting documents as appendices

**For portal-entry grants**: Puppeteer headless print
- Render completed form in browser
- Print to PDF via Puppeteer
- Use as review/approval document (not submission)

**Phase 2 consideration**: Playwright portal automation (only for portals that allow automation)

**Implementation** (Week 4):
```typescript
// PDF generation endpoint
POST /api/applications/{id}/export?format=pdf

// react-pdf template
<PDFDocument>
  <Page size="A4">
    <Header grantName={grant.name} />
    {formData.steps.map(step => (
      <Section title={step.name}>
        {step.fields.map(field => (
          <Field label={field.label} value={field.value} />
        ))}
      </Section>
    ))}
  </Page>
  {supportingDocs.map(doc => (
    <Appendix document={doc} />
  ))}
</PDFDocument>
```

### Consequences

* **Pros**:
  - react-pdf gives precise control over formatting
  - Matches government portal styling (stakeholder requirement)
  - Includes supporting documents automatically
  - Client-side generation (no backend needed initially)
  - Digital signature support (react-pdf plugins available)

* **Cons / risks**:
  - Duplication: form layout in React + PDF layout (mitigated: shared data model)
  - PDFs must be manually uploaded to portals (acceptable for prototype)
  - Large PDFs (50+ pages) can be slow to generate (mitigated: show loading state)

* **Supersedes**: —

### Compliance / Verification

**Evidence Files**:
- `front/grant-portal/lib/pdf/templates/GrantApplicationPDF.tsx` - react-pdf template
- `front/grant-portal/app/api/applications/[id]/export/route.ts` - Export endpoint

**Verification**:
- Week 4: Export IGP application to PDF
- Week 4: PDF matches government portal format (stakeholder review)
- Week 4: Supporting documents appear as appendices

**Libraries**:
```json
{
  "@react-pdf/renderer": "^3.1.0",
  "puppeteer": "^21.0.0"  // Optional for Puppeteer approach
}
```

**AI Agent Guidance**: Use react-pdf for PDF generation. Create template in `lib/pdf/templates/{grant-id}PDF.tsx` for each grant. Render form data into PDF template. For prototype, PDF is for stakeholder review and portal upload (not automated submission). In Phase 3, consider Playwright for automated portal submission (only for grants that permit it).

---

## ADR-1006 — URL Structure for Multi-Grant Multi-Client Scale

<a id="adr-1006"></a>
**Date**: 2025-11-13
**Status**: Accepted
**Owner**: Grant-Harness Team

### Context

Phase 1 prototype uses URL structure `/applications/igp-commercialisation/step1` which is grant-specific. This works for demonstrating the form pattern but doesn't scale to production requirements:

**Scalability Problems**:
1. **Multiple grants**: Platform will have 50-100+ different grants, each needs unique forms
2. **Multiple clients per grant**: Same grant (e.g., IGP) will have 10-50+ companies applying simultaneously
3. **Multiple applications per client**: Each company may apply to 5-10 grants, need to distinguish between applications
4. **Resume vs New**: Need to differentiate "start new application" vs "resume existing application"

**Current Limitations**:
- No way to distinguish between applications from different companies
- No UUID/ID to identify specific application instances
- LocalStorage key is grant-specific, not application-specific
- No dashboard to list user's applications

### Alternatives

**Option 1: Keep current structure (Prototype only)**:
- `/applications/[grantId]/step[N]`
- Pros: Simple for prototype, no refactoring needed
- Cons: Doesn't scale, migration required in Phase 2

**Option 2: Add application ID immediately**:
- `/applications/[applicationId]/step[N]`
- Pros: Scalable from day 1, no migration needed
- Cons: Premature optimization, adds complexity to prototype (no user accounts yet)

**Option 3: Hybrid approach - prep for migration (chosen)**:
- **Phase 1 (Prototype)**: Keep `/applications/[grantId]/step[N]`
- **Phase 2 (Production)**: Migrate to `/applications/[applicationId]/step[N]`
- Pros: Simple now, clear migration path
- Cons: One-time migration effort (acceptable)

### Decision

**Phase 1 URL Structure** (Current - No changes):
```
/applications/igp-commercialisation/step1
/applications/igp-commercialisation/step2
...
/applications/bbi-initiative/step1
```

**LocalStorage keys**:
```typescript
grant_portal_igp_commercialisation_form    // Form data
grant_portal_igp_current_step              // Current step
```

**Phase 2 URL Structure** (Future - when Firebase auth added):
```
/applications/new/[grantId]              → Redirect to /applications/[newUUID]/step1
/applications/[applicationId]/step[N]    → Resume existing application
/dashboard/applications                   → List all user's applications
```

**Migration Path**:
1. Add Firebase Authentication (user accounts)
2. Create `applications` collection in Firestore with schema:
   ```typescript
   {
     id: UUID,                    // Application ID
     userId: string,              // Owner
     grantId: string,             // e.g., "igp-commercialisation"
     companyId: string,           // e.g., "c-emew"
     status: "draft" | "submitted" | "approved",
     currentStep: number,
     formData: {...},             // All steps
     createdAt: timestamp,
     updatedAt: timestamp
   }
   ```
3. When user signs up, detect LocalStorage applications → prompt to import:
   ```typescript
   const localApps = detectLocalStorageApplications(); // [{grantId: "igp-commercialisation", formData: {...}}]
   if (localApps.length > 0) {
     showImportPrompt("We found 2 draft applications. Import them?");
     // Create Firestore documents with new UUIDs
   }
   ```
4. Update routing:
   ```typescript
   // Old URL redirect
   /applications/igp-commercialisation/step1
     → Redirect to /applications/new/igp-commercialisation
     → Create new application UUID
     → Redirect to /applications/{newUUID}/step1

   // New URL pattern
   /applications/[applicationId]/step[N]  ← Primary pattern
   ```

**Benefits of delayed migration**:
- Prototype stays simple (no UUID generation, no database)
- Form pattern proven before scaling complexity
- LocalStorage → Firestore migration is one-time operation
- URL structure change is backward-compatible (old URLs redirect)

### Consequences

* **Pros**:
  - Prototype complexity minimized (focus on form pattern)
  - Clear migration path documented
  - LocalStorage data preserved (imported to Firestore in Phase 2)
  - URL pattern extensible (supports 100+ grants, 1000+ applications)

* **Cons / risks**:
  - One-time migration effort in Phase 2 (acceptable: ~1-2 days)
  - Old URLs will need redirects (mitigated: automatic redirect)
  - Users with draft applications must import manually (mitigated: auto-detect and prompt)

* **Supersedes**: —

### Compliance / Verification

**Phase 1 (Current)**:
- ✅ URLs follow pattern: `/applications/[grantId]/step[N]`
- ✅ LocalStorage keys include grant ID
- ✅ No application ID or user ID required

**Phase 2 (Migration checklist)**:
- [ ] Firebase Authentication configured
- [ ] Firestore `applications` collection created
- [ ] LocalStorage detection and import flow implemented
- [ ] URL routing updated to `/applications/[applicationId]/step[N]`
- [ ] Old URLs redirect to new pattern
- [ ] Dashboard page created (`/dashboard/applications`)

**Evidence Files** (Phase 2):
- `front/grant-portal/app/(protected)/applications/[applicationId]/step[N]/page.tsx`
- `front/grant-portal/app/(protected)/dashboard/applications/page.tsx`
- `front/grant-portal/lib/migrations/importLocalStorageApplications.ts`

**AI Agent Guidance**: For Phase 1, keep URLs simple (`/applications/[grantId]/step[N]`). Do NOT add application IDs or UUIDs yet. In Phase 2, when adding Firebase auth, implement migration per this ADR. Always use application ID in Firestore (never rely on grant ID alone). When creating new applications, generate UUID and redirect to `/applications/[UUID]/step1`.

---

## ADR-1007 — Playwright MCP Browser Testing Before PR

<a id="adr-1007"></a>
**Date**: 2025-11-15
**Status**: Accepted
**Owner**: Grant-Harness Development Team

### Context

Form validation issues (e.g., disabled Next buttons, field validation failures) are NOT visible in code review. Issue #2 demonstrated this: the Step 2 Next button remained disabled despite all fields being filled because `mode: "onChange"` was missing from the `useForm` configuration. This was only discovered during manual user testing, delaying delivery.

As the project scales with multiple complex forms (Steps 1-7 for IGP, future grants), we need **automated, repeatable browser testing that provides evidence before PR review**.

### Alternatives

1. **Manual browser testing only** - Not scalable, no evidence trail, prone to human error
2. **Static Playwright E2E tests** - Requires test code maintenance, doesn't provide visual evidence for PR review
3. **Screenshot testing tools (Percy, Chromatic)** - Expensive, focused on visual regression not functional validation
4. **Cypress** - Similar to Playwright but Playwright MCP provides direct integration with Claude Code workflows

### Decision

**MANDATORY before creating any frontend form PR**: Use Playwright MCP browser automation tools to test complete user flows and capture evidence.

**Required workflow**:
1. Start dev server: `npm run dev` in `front/grant-portal/`
2. Use Playwright MCP tools in Claude Code session:
   - `mcp__Claude_Playwright__browser_navigate` - Navigate to form
   - `mcp__Claude_Playwright__browser_type` - Fill text fields
   - `mcp__Claude_Playwright__browser_click` - Click buttons/radios/checkboxes
   - `mcp__Claude_Playwright__browser_snapshot` - Verify page state
   - `mcp__Claude_Playwright__browser_take_screenshot` - Capture evidence
3. Test complete user flow from start to finish with realistic mock data
4. Verify Next/Submit buttons become enabled when forms are valid
5. Save test evidence:
   - Screenshots → `.docs/screenshots/test-evidence/step{N}-{state}.png`
   - Form data JSON → `.docs/screenshots/test-evidence/{form-name}-test-data.json`
6. Reference evidence in PR description with links to screenshots and JSON

### Consequences

* **Pros**:
  - Catches validation issues before PR review (saves reviewer time)
  - Provides visual evidence that forms work end-to-end
  - Scales with project growth (automated testing beats manual)
  - Integrates directly into Claude Code workflow (no context switching)
  - Creates artifact trail for QA and stakeholder review
* **Cons / risks**:
  - Adds ~5-10 minutes per PR for browser testing
  - Requires Playwright MCP server to be configured
  - Screenshots/JSON files increase repo size (mitigated by `.gitignore` if needed)
* **Supersedes**: None (new requirement)
* **Superseded by**: —

### Compliance / Verification

**PR Checklist** (enforced in `.cursor/rules/rules.mdc` and `CLAUDE.md`):
- [ ] Playwright MCP used to fill all form steps with mock data
- [ ] Screenshots captured for each step → `.docs/screenshots/test-evidence/`
- [ ] Test data JSON created → `.docs/screenshots/test-evidence/{form-name}-test-data.json`
- [ ] PR description includes links to screenshots and JSON
- [ ] All Next/Submit buttons confirmed to enable when valid

**Evidence Format** (from `.docs/screenshots/test-evidence/{form-name}-test-data.json`):
```json
{
  "test_session": {
    "date": "2025-11-15T02:36:00Z",
    "tester": "Claude Code with Playwright MCP",
    "form": "IGP Commercialisation Application",
    "status": "Completed Steps 1-7"
  },
  "step1_eligibility": { "entityType": "Company incorporated in Australia", ... },
  "step2_organization": { "abn": "11111111111", ... },
  "test_notes": {
    "playwright_mcp_tools_used": ["browser_navigate", "browser_click", ...]
  }
}
```

**Validation**:
- ✅ Test evidence files present in `.docs/screenshots/test-evidence/`
- ✅ PR description references screenshot URLs and JSON file
- ✅ JSON file contains complete test session metadata

**Reference Pattern**: Based on [OneRedOak/claude-code-workflows design-review](https://github.com/OneRedOak/claude-code-workflows/tree/main/design-review) workflow pattern.

---

## ADR-1008 — Test Evidence Organization by Grant

<a id="adr-1008"></a>
**Date**: 2025-11-15
**Status**: Accepted
**Owner**: Grant-Harness Development Team

### Context

Current test evidence organization (`.docs/screenshots/test-evidence/`) dumps all screenshots and JSON files into a single flat directory. This creates problems:

1. **No grant identification**: Cannot tell which grant a screenshot belongs to without opening files
2. **No versioning**: Multiple test runs overwrite previous evidence, losing history
3. **No discoverability**: Cannot quickly find "latest IGP test" or "all BBI tests"
4. **Poor PR references**: PR descriptions must link to individual files, not test sessions
5. **Scaling issues**: With 10-20 grants tested repeatedly, directory becomes unmanageable

Example problem from Issue #2: Screenshots named `step1-completed.png`, `step2-filled.png` etc. with no indication they're for IGP grant, no timestamp, no test session context.

### Alternatives

**Option 1: Flat directory with naming convention** (current):
```
.docs/screenshots/test-evidence/
├── igp-step1-completed.png
├── igp-step2-filled.png
├── igp-form-test-data.json
├── bbi-step1-completed.png
...
```
- Pros: Simple, no folders
- Cons: Still hard to find specific test sessions, no versioning

**Option 2: Grant-based folders with date-versioned sessions** (chosen):
```
.docs/screenshots/test-evidence/
├── igp-commercialisation/
│   ├── 2025-11-15-session-001/
│   │   ├── metadata.json
│   │   ├── step1-completed.png
│   │   ├── step7-complete.png
│   │   └── form-data.json
│   └── 2025-11-16-session-002/
│       └── ...
├── bbi-initiative/
│   └── 2025-11-17-session-001/
│       └── ...
└── README.md
```
- Pros: Clear organization, versioning, discoverable, scalable
- Cons: Deeper folder structure

**Option 3: Database-backed test evidence**:
- Pros: Queryable, filterable
- Cons: Overkill for prototype, evidence not in git

### Decision

Organize test evidence by **grant ID** with **date-versioned test sessions**:

**Directory Structure**:
```
.docs/screenshots/test-evidence/
├── {grant-id}/                     # e.g., igp-commercialisation
│   ├── {YYYY-MM-DD}-session-{NNN}/ # e.g., 2025-11-15-session-001
│   │   ├── metadata.json           # Test session info
│   │   ├── step{N}-{state}.png     # Screenshots
│   │   └── form-data.json          # Complete form data
│   └── {YYYY-MM-DD}-session-{NNN}/ # Additional test runs
│       └── ...
├── {another-grant-id}/
│   └── ...
└── README.md                        # Explains structure and usage
```

**metadata.json** (required in every session):
```json
{
  "test_session": {
    "session_id": "2025-11-15-session-001",
    "grant_id": "igp-commercialisation",
    "grant_name": "Industry Growth Program - Commercialisation Stream",
    "date": "2025-11-15T02:59:00Z",
    "tester": "Claude Code with Playwright MCP",
    "test_type": "End-to-end form population with browser automation",
    "status": "ALL 7 STEPS COMPLETED - Submit button enabled",
    "total_steps": 7,
    "steps_completed": 7,
    "playwright_mcp_tools_used": [
      "browser_navigate", "browser_click", "browser_type",
      "browser_snapshot", "browser_take_screenshot"
    ],
    "duration_minutes": 15,
    "blocking_issues_encountered": ["LocalStorage hydration causing validation to not trigger"],
    "workaround_applied": "Navigate directly between steps using page.goto()"
  },
  "evidence_files": {
    "screenshots": [
      "step1-completed.png",
      "step2-filled.png",
      "step3-filled.png",
      "step4-empty.png",
      "step5-empty.png",
      "step6-empty.png",
      "step7-complete.png",
      "submit-confirmation.png"
    ],
    "form_data": "form-data.json",
    "submission_data": "Outcome of clicking Submit button (localStorage/API response/alert)"
  },
  "mock_data_source": {
    "company": "EMEW Technologies Pty Ltd",
    "reference": "Based on EMEW corporate profile from .docs/context/emew-context/"
  }
}
```

**form-data.json** (complete form data for reproducibility):
```json
{
  "step1_eligibility": { "entityType": "Company incorporated in Australia", ... },
  "step2_organization": { "abn": "11111111111", ... },
  ...
  "step7_contact_declaration": { "primaryContact": { ... } }
}
```

**README.md** (at root of test-evidence/):
```markdown
# Test Evidence Directory

## Structure

Each grant has its own folder named by grant ID (e.g., `igp-commercialisation`).
Each test session is a date-versioned subfolder (e.g., `2025-11-15-session-001`).

## Finding Test Evidence

- **Latest IGP test**: Look in `igp-commercialisation/` for most recent date
- **All BBI tests**: Browse `bbi-initiative/` folder
- **Specific test session**: Navigate to `{grant-id}/{date}-session-{nnn}/`

## Files in Each Session

- `metadata.json` - Test session info (status, duration, tools used)
- `step{N}-{state}.png` - Screenshots of each form step
- `submit-confirmation.png` - Screenshot of submission outcome (MANDATORY)
- `form-data.json` - Complete form data for reproducibility

## PR References

When creating PR, link to specific test session:
```
Test Evidence: `.docs/screenshots/test-evidence/igp-commercialisation/2025-11-15-session-001/`
- All 7 steps completed: [metadata.json](...)
- Submit button enabled: [step7-complete.png](...)
```
```

**Migration from current structure**:
1. Move existing evidence to grant-specific folders:
   ```bash
   mkdir -p .docs/screenshots/test-evidence/igp-commercialisation/2025-11-15-session-001/
   mv .docs/screenshots/test-evidence/step*.png .docs/screenshots/test-evidence/igp-commercialisation/2025-11-15-session-001/
   mv .docs/screenshots/test-evidence/igp-form-test-data.json .docs/screenshots/test-evidence/igp-commercialisation/2025-11-15-session-001/form-data.json
   # Create metadata.json from test data JSON
   ```
2. Delete old flat files
3. Create README.md explaining structure

### Consequences

* **Pros**:
  - **Discoverability**: Easy to find "all IGP tests" or "latest BBI test"
  - **Versioning**: Test history preserved (compare session-001 vs session-002)
  - **Scalability**: 20 grants × 5 test sessions = 100 sessions, still organized
  - **PR references**: Link to entire session folder, not individual files
  - **Reproducibility**: metadata.json + form-data.json = complete test context
  - **Pattern reuse**: Same structure for all grants (consistency)

* **Cons / risks**:
  - Deeper folder nesting (3 levels) - acceptable for clarity
  - Migration effort for existing evidence - one-time cost (~10 minutes)
  - Requires discipline to follow naming convention - enforced in CLAUDE.md

* **Supersedes**: Flat test evidence directory structure
* **Superseded by**: —

### Compliance / Verification

**Mandatory PR Checklist** (enforced in `.cursor/rules/rules.mdc` and `CLAUDE.md`):
- [ ] Test evidence organized in `.docs/screenshots/test-evidence/{grant-id}/{YYYY-MM-DD}-session-{NNN}/`
- [ ] `metadata.json` present with test session info
- [ ] `form-data.json` contains complete form data
- [ ] All screenshots follow naming pattern `step{N}-{state}.png`
- [ ] **`submit-confirmation.png` present showing submission outcome (MANDATORY)**
- [ ] **Submit button clicked and data outcome documented in metadata.json (MANDATORY)**
- [ ] PR description links to specific test session folder

**Validation Script** (future enhancement):
```bash
# Verify test evidence structure
python scripts/verify-test-evidence.py .docs/screenshots/test-evidence/
# Checks:
# - Each grant folder has at least one session
# - Each session has metadata.json + form-data.json
# - Screenshot files referenced in metadata.json exist
```

**AI Agent Guidance**:

**CRITICAL**: Always organize test evidence by grant ID and test session date.

**Test Evidence Workflow**:
1. Before starting Playwright MCP test, determine session ID:
   ```
   grant_id = "igp-commercialisation"  # From grant being tested
   date = "2025-11-15"                 # Today's date
   session_num = check_existing_sessions(grant_id, date) + 1  # Increment
   session_id = f"{date}-session-{session_num:03d}"  # e.g., "2025-11-15-session-001"
   evidence_dir = f".docs/screenshots/test-evidence/{grant_id}/{session_id}/"
   ```

2. Create evidence directory:
   ```bash
   mkdir -p .docs/screenshots/test-evidence/igp-commercialisation/2025-11-15-session-001/
   cd .docs/screenshots/test-evidence/igp-commercialisation/2025-11-15-session-001/
   ```

3. Run Playwright MCP test, filling ALL form steps with mock data

4. **CLICK SUBMIT BUTTON** - Use `browser_click` to click the Submit Application button

5. **CAPTURE SUBMISSION OUTCOME** - Use `browser_take_screenshot` to save `submit-confirmation.png` showing alert/confirmation/response

6. **DOCUMENT DATA OUTCOME** - Record what happened in metadata.json (localStorage save, API response, alert message, etc.)

7. Create `metadata.json` with test session info (template above)

8. Create `form-data.json` with complete form data

6. Update PR description with link to test session folder:
   ```markdown
   ## Test Evidence

   Complete 7-step test session: `.docs/screenshots/test-evidence/igp-commercialisation/2025-11-15-session-001/`

   - **Status**: ✅ ALL 7 STEPS COMPLETED
   - **Submit button**: ENABLED (see [step7-complete.png](...))
   - **Test duration**: 15 minutes
   - **Mock data**: EMEW Technologies Pty Ltd

   Files:
   - [metadata.json](...) - Test session details
   - [form-data.json](...) - Complete form data
   - [step7-complete.png](...) - Final state with Submit enabled
   ```

**Never** save test evidence to flat directory. **Always** use grant-specific folders with date-versioned sessions.

---
