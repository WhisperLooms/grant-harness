---
description: Grant Prototype Tactical Architectural Decision Records
globs:
alwaysApply: false
---

# Architecture Decision Log - Grant Prototype (Phase 1)

<!--
ADR_AGENT_PROTOCOL v1.0

You (the agent) manage this file as the single source of truth for all Grant Prototype tactical ADRs.

NUMBER RANGE CONVENTION
- Platform ADRs: ADR-0001 to ADR-0999 (.cursor/rules/platform/ADR.mdc)
- Frontend ADRs: ADR-1000 to ADR-1999 (.cursor/rules/frontend/ADR.mdc)
- Backend Infrastructure: ADR-2000 to ADR-2049 (.cursor/rules/backend/ADR.mdc)
- Backend Grant Prototype: ADR-2050 to ADR-2099 (.cursor/rules/backend/grant-prototype/ADR.mdc)
- Backend Grant ADK: ADR-2100 to ADR-2499 (.cursor/rules/backend/ADR.mdc)

INVARIANTS
- Keep this exact file structure and headings.
- All ADR entries use H2 headings: "## ADR-XXXX — <Title>" (4-digit zero-padded ID).
- Grant Prototype ADRs MUST use numbers 2050-2099 only.
- Allowed Status values: Proposed | Accepted | Superseded
- Date format: YYYY-MM-DD
- New entries must be appended to the END of the file.
- The Index table between the INDEX markers must always reflect the latest state and be sorted by ID desc (newest on top).
- Each ADR MUST contain: Date, Status, Owner, Context, Decision, Consequences.
- Each ADR must include an explicit anchor `<a id="adr-XXXX"></a>` so links remain stable.

IMPORTANT: These are TACTICAL decisions for Phase 1 prototype only. Many may be superseded by Grant ADK decisions in Phase 2.

HOW TO ADD A NEW ADR
1) Read the whole file.
2) Compute next ID:
   - Scan for headings matching: ^## ADR-(\d{4}) — .+$
   - next_id = (max captured number) + 1, left-pad to 4 digits.
   - Ensure ID is in range 2050-2099.
3) Create a new ADR section using the "New ADR Entry Template" below.
   - Place it AFTER the last ADR section in the file.
   - Add an `<a id="adr-XXXX"></a>` line immediately below the heading.
4) Update the Index (between the INDEX markers):
   - Insert/replace the row for this ADR keeping the table sorted by ID descending.
   - Title in the Index MUST link to the anchor: [<Title>](#adr-XXXX)
   - If this ADR supersedes another: set "Supersedes" in this row, and update that older ADR:
       a) Change its Status to "Superseded"
       b) Add "Superseded by: ADR-XXXX" in its Consequences block
       c) Update the older ADR's Index row "Superseded by" column to ADR-XXXX
5) Validate before saving:
   - Exactly one heading exists for ADR-XXXX
   - All required fields are present and non-empty
   - Index contains a row for ADR-XXXX and remains properly sorted
6) Concurrency resolution:
   - If a merge conflict or duplicate ID is detected after reading: recompute next_id from the current file state, rename your heading, anchor, and Index row accordingly, and retry once.

COMMIT MESSAGE SUGGESTION
- "ADR-XXXX: <Short Title> — <Status>"

END ADR_AGENT_PROTOCOL
-->

## Index

<!-- BEGIN:ADR_INDEX -->

| ID   | Title                                                      | Date       | Status   | Supersedes | Superseded by |
| ---- | ---------------------------------------------------------- | ---------- | -------- | ---------- | ------------- |
| 2050 | [crawl4ai for AI-Powered Web Scraping](#adr-2050)         | 2025-11-12 | Accepted |            |               |

<!-- END:ADR_INDEX -->

---

## New ADR Entry Template (copy for each new decision)

> Replace placeholders, keep section headers. Keep prose concise.

```

## ADR-XXXX — <Short, specific title>

<a id="adr-XXXX"></a>
**Date**: YYYY-MM-DD
**Status**: Proposed | Accepted | Superseded
**Owner**: <Name>

### Context

<1–3 sentences: what changed or what forces drive this decision now>

### Alternatives

<Quick bullet list of alternatives considered, and why they were rejected.>

### Decision

<Single clear decision in active voice; make it testable/verifiable>

### Consequences

* **Pros**: <benefit 1>, <benefit 2>
* **Cons / risks**: <cost 1>, <risk 1>
* **Supersedes**: ADR-NNNN (if any)
* **Superseded by**: ADR-MMMM (filled later if replaced)

### (Optional) Compliance / Verification

<How we'll check this is honored: tests, checks, fitness functions, runbooks>

```

---

<!-- Grant Prototype tactical ADRs will be added below this line -->

## ADR-2050 — crawl4ai for AI-Powered Web Scraping

<a id="adr-2050"></a>
**Date**: 2025-11-12
**Status**: Accepted
**Owner**: Grant-Harness Team

### Context

Phase 1 prototype requires scraping grant data from 50+ Australian government websites with varying structures (static HTML, JavaScript SPAs, PDFs). Initial plan used Scrapy framework, but many government sites have complex layouts requiring intelligent extraction. Need a scraping solution that can handle both structured and unstructured content efficiently.

### Alternatives

* **Scrapy (original plan)**: Industry-standard framework, good for structured sites, but requires custom parsers for each site. Poor handling of JavaScript-heavy sites and PDF content extraction.
* **Requests + BeautifulSoup**: Simplest approach, but entirely manual parsing. High maintenance burden for 50+ sources.
* **Playwright only**: Handles JavaScript well but expensive (browser overhead), no built-in intelligent extraction, requires explicit selectors.
* **crawl4ai (chosen)**: LLM-powered extraction strategy, handles both static and dynamic content, uses Gemini API (already available), reduces custom parser code.

### Decision

Use **crawl4ai with Gemini-powered LLM extraction** for all grant and company website scraping in Phase 1 prototype.

Implementation details:
- Configure crawl4ai with `google/gemini-1.5-pro` provider using existing `GOOGLE_API_KEY`
- Use `LLMExtractionStrategy` with structured prompts for grant list extraction and detailed scraping
- Fallback to Playwright MCP for sites where crawl4ai fails
- Remove Scrapy dependency from `pyproject.toml`
- Create base crawler class in `back/grant-prototype/scrapers/base_crawler.py`

### Consequences

* **Pros**:
  - Intelligent extraction reduces custom parser code by ~70%
  - Single LLM (Gemini) for both scraping and matching simplifies architecture
  - Handles JavaScript sites without full browser overhead (crawl4ai optimized)
  - Natural language extraction prompts easier to maintain than XPath/CSS selectors
  - No additional API costs (using existing Gemini quota)

* **Cons / risks**:
  - LLM extraction adds latency vs pure HTML parsing (~2-3s per page vs <1s)
  - Dependent on LLM quality for extraction accuracy (mitigated by Gemini 1.5 Pro performance)
  - Less deterministic than explicit selectors (mitigated by structured prompts and validation)
  - crawl4ai is newer library vs mature Scrapy ecosystem (mitigated by Playwright fallback)

* **Supersedes**: Initial Scrapy-based scraping plan (not yet implemented as ADR)

### Compliance / Verification

- **Week 1 deliverable**: Successful extraction of 10+ grants from GrantConnect using crawl4ai
- **Validation**: Compare crawl4ai extraction accuracy against manually verified grant data (target: >95% field accuracy)
- **Performance**: Monitor extraction latency; if >5s per page consistently, optimize prompts or implement caching
- **Fallback testing**: Verify Playwright MCP fallback works for at least 1 complex site by Week 2

### Migration Notes

Changes from original plan:
- `scrapy>=2.11.0` removed from dependencies
- Added: `crawl4ai>=0.2.0`, `aiohttp>=3.9.0`, `playwright>=1.40.0`
- Scraper modules use async patterns instead of Scrapy's event-driven architecture
- `.env` updated with `CRAWL4AI_MODEL=gemini-1.5-pro` configuration

---
